{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2d27f90-2ba8-444e-8d02-e66dc0d131b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "017b838e-7c2b-49d4-8a62-0d221a004fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr.\n",
      "Anubhav\n",
      "Gupta\n",
      "loves\n",
      "coding\n",
      ".\n",
      "He\n",
      "did\n",
      "a\n",
      "lots\n",
      "of\n",
      "DSA\n",
      "problem\n",
      "solving\n",
      "in\n",
      "this\n",
      "year\n",
      "2025\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "text = \"Mr. Anubhav Gupta loves coding. He did a lots of DSA problem solving in this year 2025.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2fafcb0-7415-4185-8714-fbb1152cc6f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "151bacc2-f844-4dad-80b1-b35f3e65a3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "146bd483-baa9-4fcf-91ec-0a36d1ccf0e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff7c5881-2af1-4f6b-a6c3-3c77a13b2c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x202e88e6cf0>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x202e88e6210>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x202e7b26880>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x202e7acf950>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x202e808ba10>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x202e7b269d0>)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4aed9093-0bc2-44d3-902f-c6aa7dbf8c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr.  |  PROPN  |  Mr.\n",
      "Anubhav  |  PROPN  |  Anubhav\n",
      "Gupta  |  PROPN  |  Gupta\n",
      "loves  |  VERB  |  love\n",
      "coding  |  VERB  |  cod\n",
      ".  |  PUNCT  |  .\n",
      "He  |  PRON  |  he\n",
      "did  |  VERB  |  do\n",
      "a  |  DET  |  a\n",
      "lots  |  NOUN  |  lot\n",
      "of  |  ADP  |  of\n",
      "DSA  |  PROPN  |  DSA\n",
      "problem  |  NOUN  |  problem\n",
      "solving  |  VERB  |  solve\n",
      "in  |  ADP  |  in\n",
      "this  |  DET  |  this\n",
      "year  |  NOUN  |  year\n",
      "2025  |  NUM  |  2025\n",
      ".  |  PUNCT  |  .\n"
     ]
    }
   ],
   "source": [
    "text = \"Mr. Anubhav Gupta loves coding. He did a lots of DSA problem solving in this year 2025.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "for token in doc:\n",
    "    print(token,\" | \",token.pos_,\" | \",token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1be0a135-60e8-45c5-8897-11245bbd7b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla Inc  |  ORG  |  Companies, agencies, institutions, etc.\n",
      "Twitter Pvt Ltd  |  ORG  |  Companies, agencies, institutions, etc.\n",
      "$5 billion  |  MONEY  |  Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Tesla Inc is going to accurire Twitter Pvt Ltd for $5 billion\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text,\" | \",ent.label_,\" | \",spacy.explain(ent.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38064f04-31a4-46ef-aad6-1b87d7ffca6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ner']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "nlp.add_pipe(\"ner\", source=source_nlp)\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2711e5a5-898b-476f-a20a-c36ac9299533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla Inc ORG\n",
      "$45 billion MONEY\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Tesla Inc is going to acquire twitter for $45 billion\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e95bde3-1e79-45d5-b548-58dd5b6eaa9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7bd3f42-c13b-45bd-b5bc-163db9a400fb",
   "metadata": {},
   "source": [
    "Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25cd5624-36c0-4358-adb6-3699ddcf85d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6b452592-e5ee-4569-ba25-3d559790fcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proper Nouns:  [Ravi, Raju, Paris, London, Dubai, Rome, Mohan, Hyderabad]\n",
      "Count:  8\n"
     ]
    }
   ],
   "source": [
    "text = ''' Ravi and Raju are the best friends from school days.They wanted to go for a world tour and \n",
    "visit famous cities like Paris, London, Dubai, Rome etc and also they called their another friend Mohan to take part of this world tour.\n",
    "They started their journey from Hyderabad and spent next 3 months travelling all the wonderful cities in the world and cherish a happy moments!\n",
    "'''\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "count = 0\n",
    "nouns = []\n",
    "for token in doc:\n",
    "    if token.pos_ == 'PROPN':\n",
    "        count+=1\n",
    "        nouns.append(token)\n",
    "\n",
    "print(\"Proper Nouns: \" , nouns)\n",
    "print(\"Count: \", len(nouns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b045d8b-9e9f-49c1-9e15-a81207bc6ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proper Nouns:  [Tesla, Walmart, Amazon, Microsoft, Google, Infosys, Reliance, HDFC Bank, Hindustan Unilever, Bharti Airtel]\n",
      "Count:  10\n"
     ]
    }
   ],
   "source": [
    "text = '''The Top 5 companies in USA are Tesla, Walmart, Amazon, Microsoft, Google and the top 5 companies in \n",
    "India are Infosys, Reliance, HDFC Bank, Hindustan Unilever and Bharti Airtel'''\n",
    "\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "\n",
    "companies = []\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == 'ORG':\n",
    "        count+=1\n",
    "        companies.append(ent)\n",
    "\n",
    "print(\"Proper Nouns: \" , companies)\n",
    "print(\"Count: \", len(companies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0dc63c-0bb4-4d9d-ae99-1c80d0ad6e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
